-An operating system is software that manages 
computer hardware and acts as an intermediary between the programs and the hardware.

-Kernel is the core part of the operating 
system that is always running that manages computer hardware and the computer can't run without it.


()()Section Interrupts:

-An interrupt is a mechanism that allows the 
CPU to work in parallel with devices by sending 
it a signal when something important happens. 
The CPU can then pause what it’s doing and handle the event.

- An interrupt is a signal sent to the CPU that tells it to 
pause what it’s doing and handle something important right now.


-When someone presses the "A" key on the keyboard:

1. The **keyboard controller** detects the key press.
2. The controller stores the value of the keystroke in its **buffer**.
3. The controller sends an **interrupt signal** to the CPU.
4. The CPU temporarily **pauses its current task** saves state and calls the **interrupt handler**.
5. The **interrupt handler** invokes the **keyboard driver**.
6. The driver reads the keystroke from the controller's buffer.
7. Finally, the driver sends the keystroke information to the **operating system** for use by programs.

Interrupt Service Routine (ISR) = interrupt handler


(Interrupt Vector Table)
Interrupts need to be handled fast, because they happen very frequently.
A naïve way would be to call a generic routine that looks at what caused the interrupt, then branches to the right handler.
But that’s too slow.

Instead, computers use an Interrupt Vector Table (IVT):
It’s an array stored in low memory.
Each entry is a pointer (address) to the correct ISR for a device.
When an interrupt happens, the hardware gives a unique number (interrupt request number).
That number is used as an index into the table → instantly finds the correct ISR.



The CPU interrupt request line is a physical wire connected to the CPU.
The CPU checks this wire after every instruction. If the line is high, it means there is an interrupt.
The CPU reads the interrupt number from the device.
It then looks up a special table called the interrupt vector.
This table tells the CPU where the code is to handle this specific interrupt, called the interrupt handler.
The interrupt handler saves the CPU’s current state so it can resume later.
It determines what caused the interrupt and performs the required task.
After finishing, the handler restores the CPU’s state.
The CPU then returns to the original task it was executing before the interrupt.
Once the handler is done, the device knows its request has been handled.


what is the above system lacking? 
-1. We need the ability to defer*(not allow) interrupt handling during critical processing.
-2. We need an efficient way to dispatch to the proper interrupt handler for a device *since its a single line
-3. We need multilevel interrupts, so that the operating system can distinguish between high- and low-priority
interrupts and can respond with the appropriate degree of urgency


thats why we use interrupt-controller hardware


- Two Types of CPU Interrupt Lines
-Nonmaskable Interrupt (NMI) Cannot be turned off. Reserved for critical events like unrecoverable memory errors.
CPU must respond immediately.


-Maskable Interrupt (IRQ) Can be temporarily disabled (masked) by the CPU.
Useful when executing critical instructions that must not be interrupted.
Used by most device controllers to request service.


-We have a limitation with the interrupt vector table: there aren’t enough entries to
provide a unique address for every possible device.
The solution is interrupt chaining*important by using a linked list, where a single vector table entry can point to
multiple interrupt handlers linked together.
When an interrupt occurs, the CPU follows the chain, checking each handler in turn until
it finds the one that can service the device.


()()Storage Structure:

the cpu can only load instructions from memory RAM *or DRAM
all programs must be loaded into memeroy to run

RAM is volitile cant store the bootstrap program*the program that starts the operating system so 
computers use EEPROM electrically erasable programmable read-only memory 
EEPROM is infrequently written to and is nonvolatile and slow.

memory provides array of bytes each has its own address
operations like load or store can be done

Program counter is a register inside a cpu that stores 
the memory address for next cpu instruction 
neumann cycle is when cpu stores only one next instruction in the program counter


The CPU loads instructions from memory, using the address stored in the program counter.

Von Neumann Architecture:
CPU, memory, and I/O share a single memory for instructions and data.
CPU follows the fetch–decode–execute cycle:
Fetch instruction from memory (using the Program Counter).
Decode it.
Fetch operands if needed.
Execute.
Store results back.
Memory just sees addresses, not whether they hold instructions or data.


nonvolatile memory (NVM) devices are secondary storage like hdd's or ssd's 


()()I/O Structure:

Interrupt-driven I/O
Works fine for small data.
Problem: For large data (like reading a big file), 
CPU gets too many interrupts (one per byte), 
which slows everything down.

Direct Memory Access (DMA)
Solution for bulk data transfer.
Steps:
CPU sets up buffers, pointers, and counters for the device.
Device controller moves the entire block of data directly between memory and the device.
CPU doesn’t touch each byte, so it’s free to do other tasks.
Only one interrupt is sent when the block is done.



Bus vs Switch architecture
Bus architecture → all components share the same path (bus). Only one thing can communicate at a time.
Switch architecture → multiple components can communicate at the same time, so DMA is even faster here.


()()Single-Processor Systems:

Single-Processor Systems
Definition: A system with one general-purpose CPU, and that CPU has one processing core.
Core: The part of the CPU that actually executes instructions and stores temporary data in registers.


Special-Purpose Processors
These are extra processors built for specific tasks. Examples:
Disk controller CPU (handles disk read/write requests)
Keyboard microprocessor (turns keystrokes into codes)
Graphics controller microprocessor
Characteristics:
They have a limited instruction set (they can’t run general programs or user processes).
Sometimes the OS communicates with them, sending tasks and monitoring status.
Sometimes they are fully autonomous, doing their job without OS intervention.

These special-purpose processors do not make a system multiprocessor because 
the system still has only one general-purpose CPU core.


Multiprocessor Systems

Modern computers often have multiple processors (CPUs).
Each processor may have one core (or multiple cores), and they share resources like:
Bus (communication path)
Sometimes memory, clock, or peripherals

Why use multiple processors?
Goal: Increase throughput → do more work in the same amount of time.
With N processors, you might hope the system is N times faster.
Reality: It’s less than N because:
Overhead – extra work to coordinate tasks between processors.
Resource contention – processors compete for shared memory, buses, or I/O devices.


Clock:
The clock is a timing signal that keeps all parts of the computer in sync.
When multiple processors share a clock, they operate in lockstep timing, which simplifies coordination.

Peripherals:
Peripherals are external devices connected to the computer, like:
Keyboard, mouse, printer, disk drives, network cards


Symmetric Multiprocessing (SMP)

Definition: A multiprocessor system where all CPUs are peers.
Each CPU can run any task, including:
Operating system functions
User programs

Key Features of SMP:
Each CPU has its own registers and local cache
Registers = tiny, super-fast storage inside CPU
Local cache = fast memory near the CPU for frequently used data
All CPUs share main memory
Memory is accessible by all processors through the system bus


Advantages:
Multiple processes can run simultaneously
Example: 2 CPUs → 2 processes run at the same time
Overall performance is higher because tasks can be divided

Challenges / Inefficiencies:
One CPU may be idle while another is overloaded
To avoid this, CPUs should share data structures and dynamically balance the workload
Careful programming is needed to prevent conflicts when multiple CPUs access shared memory


• CPU—The hardware that executes instructions.
• Processor—A physical chip that contains one or more CPUs.
• Core—The basic computation unit of the CPU.
• Multicore— Including multiple computing cores on the same CPU.
• Multiprocessor— Including multiple processors.

Caches in Multicore CPUs
Level 1 (L1) cache: Each core has its own private cache (small but very fast).
Level 2 (L2) cache: Shared by all cores on the chip (larger, slower than L1).
Idea: Combines fast local storage and shared storage for efficiency.

To the operating system, a multicore CPU with N cores looks like N separate CPUs.


Problem with Many CPUs in a Traditional Multiprocessor
Adding more CPUs increases computing power, but only up to a point.
Problem: All CPUs share the system bus, so too many CPUs cause contention → performance can decrease instead of increase.

NUMA (Non-Uniform Memory Access)
Idea: Give each CPU (or group of CPUs) its own local memory accessed via a fast local bus.
CPUs are connected via a shared system interconnect, so all memory is still addressable globally.

Advantages:
Fast local memory access → CPU can read/write its own memory quickly.
No contention for local memory → better scalability with more CPUs.

Drawbacks:
Remote memory access is slower → e.g., CPU0 accessing CPU3’s memory takes longer than accessing its own.
OS must carefully schedule tasks and manage memory to minimize this latency.


Blade Servers
Blade servers are systems where multiple processor boards (blades) share a single chassis.

Each blade:
Boots independently
Runs its own operating system
Some blades are multiprocessor themselves, so a blade server is like multiple independent multiprocessor systems in one chassis.